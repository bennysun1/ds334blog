[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog was designed for Dr. Matt Higham’s Data Visualization class at St. Lawrence University."
  },
  {
    "objectID": "posts/blog_post_01/index.html",
    "href": "posts/blog_post_01/index.html",
    "title": "Blog Post 01",
    "section": "",
    "text": "In this blog post, I am analyzing a data set of 2024 MLB Fantasy Baseball Projections. These projections are ‘Zeile’ Projections (sourced from FantasyPros), which are baseball specific projections derived from a consensus of 7 sources including ESPN, Draft Buddy, Baseball Think Factory, Steamer Blog, Razzball, Derek Carty, and FanGraphs. This data set consists 747 observations (players) and 17 variables which include: ‘Player’, ‘Team’, ‘Positions’, ‘AB’, ‘R’, ‘HR’, ‘RBI’, ‘SB’, ‘AVG’, ‘OBP’, ‘H’, ‘2B’, ‘3B’, ‘BB’, ‘SO’, ‘SLG’, ‘OPS’. This data set is hitter specific, so some of the variables I am most interested in include ‘AVG’ (Batting Average) and ‘OPS’ (On Base Percentage Plus Slugging Percentage). Using these variables, I aim to visualize which teams will have the strongest projected offenses.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nprojections &lt;- read_csv('/Users/bensunshine/Documents/SLU_Senior_Year/SP24/data_334/ds334blog/data/FantasyPros_2024_Projections_H.csv')\n\nRows: 747 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): Player, Team, Positions\ndbl (14): AB, R, HR, RBI, SB, AVG, OBP, H, 2B, 3B, BB, SO, SLG, OPS\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmissing_team &lt;-\n  projections %&gt;%\n  filter(is.na(Team))\n\nnum_players &lt;- nrow(projections)\n\ndivision_order &lt;- c('AL EAST', 'AL CENTRAL', 'AL WEST', 'NL EAST', 'NL CENTRAL', 'NL WEST', NA)\n\nprojections &lt;-\n  projections %&gt;%\n  filter(!is.na(Team)) %&gt;%\n  mutate(Division = case_when(\n    grepl('(BOS|NYY|TOR|BAL|TB)', Team) ~ 'AL EAST',\n    grepl('(MIN|DET|CLE|CWS|KC)', Team) ~ 'AL CENTRAL',\n    grepl('(HOU|TEX|SEA|LAA|OAK)', Team) ~ 'AL WEST',\n    grepl('(ATL|PHI|MIA|NYM|WSH)', Team) ~ 'NL EAST',\n    grepl('(MIL|CHC|CIN|PIT|STL)', Team) ~ 'NL CENTRAL',\n    grepl('(LAD|ARI|SD|SF|COL)', Team) ~ 'NL WEST'\n  )) %&gt;%\n  mutate(Division = factor(Division, levels = division_order))\n\n\nteam_avg_projections &lt;- \n  projections %&gt;%\n  group_by(Division, Team) %&gt;%\n  summarise(num_player = n(),\n            avg_hr = mean(HR),\n            avg_baa = mean(AVG),\n            avg_hits = mean(H),\n            avg_ops = mean(OPS),\n            se_baa = sqrt(\n              ((mean(AVG)/n()) * (1-(mean(AVG)/n()))) /\n                n()\n              )\n            ) %&gt;%\n  mutate(Division = factor(Division, levels = division_order),\n         lb_se_baa = avg_baa - se_baa,\n         ub_se_baa = avg_baa + se_baa)\n\n`summarise()` has grouped output by 'Division'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "posts/blog_post_01/index.html#introduction",
    "href": "posts/blog_post_01/index.html#introduction",
    "title": "Blog Post 01",
    "section": "",
    "text": "In this blog post, I am analyzing a data set of 2024 MLB Fantasy Baseball Projections. These projections are ‘Zeile’ Projections (sourced from FantasyPros), which are baseball specific projections derived from a consensus of 7 sources including ESPN, Draft Buddy, Baseball Think Factory, Steamer Blog, Razzball, Derek Carty, and FanGraphs. This data set consists 747 observations (players) and 17 variables which include: ‘Player’, ‘Team’, ‘Positions’, ‘AB’, ‘R’, ‘HR’, ‘RBI’, ‘SB’, ‘AVG’, ‘OBP’, ‘H’, ‘2B’, ‘3B’, ‘BB’, ‘SO’, ‘SLG’, ‘OPS’. This data set is hitter specific, so some of the variables I am most interested in include ‘AVG’ (Batting Average) and ‘OPS’ (On Base Percentage Plus Slugging Percentage). Using these variables, I aim to visualize which teams will have the strongest projected offenses.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nprojections &lt;- read_csv('/Users/bensunshine/Documents/SLU_Senior_Year/SP24/data_334/ds334blog/data/FantasyPros_2024_Projections_H.csv')\n\nRows: 747 Columns: 17\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (3): Player, Team, Positions\ndbl (14): AB, R, HR, RBI, SB, AVG, OBP, H, 2B, 3B, BB, SO, SLG, OPS\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmissing_team &lt;-\n  projections %&gt;%\n  filter(is.na(Team))\n\nnum_players &lt;- nrow(projections)\n\ndivision_order &lt;- c('AL EAST', 'AL CENTRAL', 'AL WEST', 'NL EAST', 'NL CENTRAL', 'NL WEST', NA)\n\nprojections &lt;-\n  projections %&gt;%\n  filter(!is.na(Team)) %&gt;%\n  mutate(Division = case_when(\n    grepl('(BOS|NYY|TOR|BAL|TB)', Team) ~ 'AL EAST',\n    grepl('(MIN|DET|CLE|CWS|KC)', Team) ~ 'AL CENTRAL',\n    grepl('(HOU|TEX|SEA|LAA|OAK)', Team) ~ 'AL WEST',\n    grepl('(ATL|PHI|MIA|NYM|WSH)', Team) ~ 'NL EAST',\n    grepl('(MIL|CHC|CIN|PIT|STL)', Team) ~ 'NL CENTRAL',\n    grepl('(LAD|ARI|SD|SF|COL)', Team) ~ 'NL WEST'\n  )) %&gt;%\n  mutate(Division = factor(Division, levels = division_order))\n\n\nteam_avg_projections &lt;- \n  projections %&gt;%\n  group_by(Division, Team) %&gt;%\n  summarise(num_player = n(),\n            avg_hr = mean(HR),\n            avg_baa = mean(AVG),\n            avg_hits = mean(H),\n            avg_ops = mean(OPS),\n            se_baa = sqrt(\n              ((mean(AVG)/n()) * (1-(mean(AVG)/n()))) /\n                n()\n              )\n            ) %&gt;%\n  mutate(Division = factor(Division, levels = division_order),\n         lb_se_baa = avg_baa - se_baa,\n         ub_se_baa = avg_baa + se_baa)\n\n`summarise()` has grouped output by 'Division'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "posts/blog_post_01/index.html#visualizations",
    "href": "posts/blog_post_01/index.html#visualizations",
    "title": "Blog Post 01",
    "section": "Visualizations",
    "text": "Visualizations\n\n# error bar plot for mean BAA\nteam_avg_projections %&gt;%\n  mutate(Team = fct_reorder(Team, avg_baa), .desc = T) %&gt;%\n  ggplot(aes(x = Team, y = avg_baa)) +\n  geom_errorbar(aes(ymin = lb_se_baa, ymax = ub_se_baa, colour = Division)) +\n  geom_point(aes(x = Team, y = avg_baa)) +\n  labs(title = \"Mean BAA by Team\",\n       y = \"Mean BAA\") +\n  theme(plot.title = element_text(hjust = 0.5),\n        legend.position = 'none') +\n  facet_wrap(~ Division, scales = 'free_y') +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThis first plot analyzes each team’s mean batting average. Each team is grouped into a faceted section of the plot according to their division. The standard error is plotted in addition to the mean batting average for each team to display the variability and confidence intervals around the averages. It can be seen the Colorado Rockies are predicted to have highest average batting average in the 2024 season. Most teams have consistent standard errors, but it appears the Milwaukee Brewers have the smallest standard error, indicating their players are likely to have batting averages closer to their mean batting average than other teams.\n\n\n# bar plot mean OPS\nteam_avg_projections %&gt;%\n  mutate(Team = fct_reorder(Team, avg_ops), .desc = T) %&gt;%\n  ggplot(aes(x = Team,\n             y = avg_ops,\n             fill = Division)) +\n  geom_col(color = 'black') +\n  labs(y = 'Mean OPS',\n       title = 'Mean OPS by Team') +\n  scale_y_continuous(n.breaks = 6) +\n  theme(plot.title = element_text(hjust = 0.5),\n        legend.position = 'none') +\n  facet_wrap(~ Division, scales = 'free_y') +\n  #coord_flip(ylim = c(0.22,0.26)) +\n  coord_flip(ylim = c(0.6,0.75)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe second plot examines each team’s mean on base percentage plus slugging percentage (OPS) using bar plots faceted by their Division. This statistic is unique because it gives insight into the likelihood of a team getting on base and generating extra base hits. Again it can be the Colorado Rockies are projected to have the highest OPS in the MLB at over 0.720. Just behind are both the Boston Red Sox and the Atlanta Braves."
  },
  {
    "objectID": "posts/blog_post_01/index.html#conclusion",
    "href": "posts/blog_post_01/index.html#conclusion",
    "title": "Blog Post 01",
    "section": "Conclusion",
    "text": "Conclusion\nBecause there are 30 teams in the MLB, I decided to facet the teams by their division to make the plots seem less cluttered. In the first plot I also utilized the error bar for displaying the standard error as presented in class. This gives us more information about the distribution of batting averages for each team, which would be lost in the summarized data. To make both graphs easily interpretable, I also arranged each faceted plot to be sorted in descending order of the statistic being examined. This makes it easy for the viewer to see which team has the highest and lowest statistics in each division. In this data set it’s important to note there were 89 players who had ‘NA’ values for their ‘Team’ variable. This is due to the fact that these players are free agents in 2024, so they are currently unassigned to a team. For simplicity, I removed these players from my analysis so I could compare teams and their current players. In the future, I would be interested in comparing each player’s and team’s projected statistics against their actual 2024 statistics. A huge amount is bet on fantasy sports, so it would be interesting to see how well these projections perform."
  },
  {
    "objectID": "posts/blog_post_04/index.html",
    "href": "posts/blog_post_04/index.html",
    "title": "Blog Post 04",
    "section": "",
    "text": "In this blog post, I analayze whether prediction markets are a better way to gauge public support for candidates than traditional polls. This analysis uses three data sources from the 2008 election cycle. The first being data from Intrade, a former Irish web-based trading exchange, sourced from Kosuke Imai (Harvard University)’s GitHub repository. Intrade operated as a prediction market where members traded contracts on the likelihood of certain events occurring. Their contracts are on a point scale of 0 to 100 points where a contract with a value of 0 suggests a given event will not occur. Intrade contracts offer an interpretation of the global market’s opinion on the probability of a particular presidential candidate winning. Variables from this data set included the date, state name, state abbreviation, price of democrat candidate’s contract, price of a republican candidate’s contract the volume of traders of democrat contracts, and volume of traders of republican contracts. The second data set used was polling data also sourced from Kosuke Imai’s github repository, that contained over 400 pollsters worth of polling data for US states. The last data set consisted of election outcome data from the 2008 and 2012 election cycles that was scraped from Wikipedia. This data included the percent of votes, number of votes, and electoral votes won by each candidate in the respective elections.\n\n## Load packages\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(plotly)\nlibrary(rvest)\nlibrary(maps)\nlibrary(tigris)\nlibrary(mapview)\nlibrary(sf)\nlibrary(usmap)\nlibrary(leaflet)\nlibrary(leafpop)\n\n\n## Data cleaning\nstate_df &lt;- ggplot2::map_data(\"state\")\n\nus_geo &lt;- tigris::states(cb = TRUE, resolution = '20m')\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |======================================================================| 100%\n\nstates_df &lt;- \n  tibble(state = state.name) %&gt;%\n  bind_cols(tibble(abb = state.abb)) %&gt;% \n  bind_rows(tibble(state = \"District of Columbia\", abb = \"DC\"))\n\nintrade08 &lt;- read_csv(\"https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/intrade08.csv\") %&gt;%\n  select(2:7) %&gt;%\n  mutate(PriceD = ifelse(is.na(PriceD), 0, PriceD),\n         PriceR = ifelse(is.na(PriceR), 0, PriceR)) %&gt;%\n  mutate(statename = as.factor(statename),\n         democrat_candidate = \"Barack Obama\",\n         republican_candidate = \"John McCain\",\n         pred_winner = case_when(\n           PriceD &gt; PriceR ~ \"democrat\",\n           PriceR &gt; PriceD ~ \"republican\",\n           .default = \"Tie\"\n         )\n  ) %&gt;%\n  rename(#\"state\" = \"statename\",\n    \"democrat\" = \"PriceD\",\n    \"republican\" = \"PriceR\") %&gt;%\n  filter(day &lt; as.Date(\"2008-11-04\"))\n\nintrade12 &lt;- read_csv(\"https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/intrade12.csv\") %&gt;%\n  select(2:7) %&gt;%\n  mutate(PriceD = ifelse(is.na(PriceD), 0, PriceD),\n         PriceR = ifelse(is.na(PriceR), 0, PriceR)) %&gt;%\n  mutate(statename = as.factor(statename),\n         democrat_candidate = \"Barack Obama\",\n         republican_candidate = \"Mitt Romney\",\n         pred_winner = case_when(\n           PriceD &gt; PriceR ~ \"democrat\",\n           PriceR &gt; PriceD ~ \"republican\",\n           .default = \"Tie\"\n         )\n  )%&gt;%\n  rename(#\"state\" = \"statename\",\n    \"democrat\" = \"PriceD\",\n    \"republican\" = \"PriceR\") %&gt;%\n  filter(day &lt; as.Date(\"2012-11-06\"))\n\npolls08 &lt;- read_csv(\"https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/polls08.csv\") %&gt;%\n  rename(\"statename\" = \"state\") %&gt;%\n  mutate(statename = as.factor(statename), \n         democrat_candidate = \"Barack Obama\",\n         republican_candidate = \"John McCain\") %&gt;%\n  left_join(states_df, by = c(\"statename\" = \"abb\")) %&gt;%\n  rename(\"democrat\" = \"Obama\",\n         \"republican\" = \"McCain\",\n         \"date\" = \"middate\") %&gt;%\n  mutate(pred_winner = case_when(\n    democrat &gt; republican ~ \"democrat\",\n    republican &gt; democrat ~ \"republican\",\n    .default = \"Tie\"\n  )) %&gt;%\n  select(-statename) %&gt;%\n  select(state, everything())\n\npolls12 &lt;- read_csv(\"https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/polls12.csv\") %&gt;%\n  select(2:6) %&gt;%\n  rename(\"statename\" = \"state\") %&gt;%\n  mutate(statename = as.factor(statename), \n         democrat_candidate = \"Barack Obama\",\n         republican_candidate = \"Mitt Romney\") %&gt;%\n  left_join(states_df, by = c(\"statename\" = \"abb\")) %&gt;%\n  rename(\"democrat\" = \"Obama\",\n         \"republican\" = \"Romney\",\n         \"date\" = \"middate\") %&gt;%\n  mutate(pred_winner = case_when(\n    democrat &gt; republican ~ \"democrat\",\n    republican &gt; democrat ~ \"republican\",\n    .default = \"Tie\"\n  )) %&gt;%\n  select(-statename) %&gt;%\n  select(state, everything())\n\n\n## '08 election\n`2008_results_scrape` &lt;- read_html(\"https://en.wikipedia.org/wiki/2008_United_States_presidential_election\")\n\n`2008_election_tables` &lt;- `2008_results_scrape` %&gt;% html_nodes(\"table.wikitable\")\n\n`2008_results_table` &lt;- `2008_election_tables`[[10]]\n\n`2008_results_df` &lt;- \n  `2008_results_table` %&gt;% \n  html_table(header = T) \n\nnew_names &lt;- c(\"Column1\", \n               \"Column2\", \n               \"Barack_Obama_Democratic\", \n               \"Barack_Obama_Democratic\",\n               \"Barack_Obama_EV\", \n               \"John_McCain_Republican\", \n               \"John_McCain_Republican\",\n               \"John_McCain_EV\", \n               \"Ralph_Nader_Independent\", \n               \"Ralph_Nader_Independent\",\n               \"Ralph_Nader_Independent\", \n               \"Bob_Barr_Libertarian\", \n               \"Bob_Barr_Libertarian\",\n               \"Bob_Barr_Libertarian\", \n               \"Chuck_Baldwin_Constitution\", \n               \"Chuck_Baldwin_Constitution\",\n               \"Chuck_Baldwin_Constitution\", \n               \"Cynthia_McKinney_Green\", \n               \"Cynthia_McKinney_Green\",\n               \"Cynthia_McKinney_Green\", \n               \"Others\",\"Others\",\"Others\", \n               \"Margin\", \"Margin\",\n               \"Total_votes\", \"Total_votes\")\n\n\n# Rename the nameless columns\nnames(`2008_results_df`)[names(`2008_results_df`) == \"\"] &lt;- new_names\n\nresults_2008_df &lt;-\n  `2008_results_df` %&gt;%\n  select(1,2,4,7,26) %&gt;%\n  rename(\"state\" = \"Column1\",\n         \"ev\" = \"Column2\",\n         \"democrat\" = \"Barack ObamaDemocratic\",\n         \"republican\" = \"John McCainRepublican\",\n         \"votes\" = \"Total votes\") %&gt;%\n  slice(-1) %&gt;%\n  mutate(votes = as.numeric(str_replace_all(votes, \",\", \"\")),\n         democrat = as.numeric(str_replace_all(democrat, \"%\", \"\")),\n         republican = as.numeric(str_replace_all(republican, \"%\", \"\")),\n         state = as.factor(state)) %&gt;%\n  mutate(state = case_when(\n    state == \"Nebraska†\" ~ \"Nebraska\",\n    state == \"Maine†\" ~ \"Maine\",\n    .default = state\n  ),\n  winner = case_when(\n    democrat &gt; republican ~ \"democrat\",\n    democrat &lt; republican ~ \"republican\",\n    .default = \"tie\")\n  )\n\nev_2008 &lt;- results_2008_df %&gt;% select(state, ev)\n\n\n\n## '12 Election\n`2012_results_scrape` &lt;- read_html(\"https://en.wikipedia.org/wiki/2012_United_States_presidential_election\")\n\n`2012_election_tables` &lt;- `2012_results_scrape` %&gt;% html_nodes(\"table.wikitable\")\n\n`2012_results_table` &lt;- `2012_election_tables`[[8]]\n\n`2012_results_df` &lt;- \n  `2012_results_table` %&gt;% \n  html_table(header = T) \n\nnames(`2012_results_df`)[4] &lt;- \"Obama_EV\"\nnames(`2012_results_df`)[7] &lt;- \"Romney_EV\"\n\n`2012_results_df` &lt;-\n  `2012_results_df` %&gt;%\n  select(1,3,4,6,7,19) %&gt;%\n  mutate(ev = ifelse(Obama_EV == \"–\", Romney_EV, Obama_EV)) %&gt;%\n  select(1,2,4,6,7)\n\n\nnew_names &lt;- c(\"state\", \"democrat\", \n               \"republican\", \"votes\")\n\n# Rename the nameless columns\nnames(`2012_results_df`)[names(`2012_results_df`) == \"\"] &lt;- new_names\n\nresults_2012_df &lt;-\n  `2012_results_df` %&gt;%\n  rename(\"state\" = \"State/District\",\n         \"democrat\" = \"Barack ObamaDemocratic\",\n         \"republican\" = \"Mitt RomneyRepublican\",\n         \"votes\" = \"Total\") %&gt;%\n  slice(-1) %&gt;%\n  mutate(votes = as.numeric(str_replace_all(votes, \",\", \"\")),\n         democrat = as.numeric(str_replace_all(democrat, \"%\", \"\")),\n         republican = as.numeric(str_replace_all(republican, \"%\", \"\")),\n         state = as.factor(state)) %&gt;%\n  filter(state != \"ME-1Tooltip Maine's 1st congressional district\" &\n           state != \"ME-2Tooltip Maine's 2nd congressional district\" &\n           state != \"NE-1Tooltip Nebraska's 1st congressional district\") %&gt;%\n  mutate(state = case_when(\n    state == \"Nebraska†\" ~ \"Nebraska\",\n    state == \"Maine†\" ~ \"Maine\",\n    state == \"District of ColumbiaDistrict of Columbia\" ~ \"District of Columbia\",\n    state == \"New Jersey[121]\" ~ \"New Jersey\",\n    state == \"New York[122]\" ~ \"New York\",\n    state == \"Ohio[123]\" ~ \"Ohio\",\n    state == \"Wisconsin[124]\" ~ \"Wisconsin\",\n    .default = state\n  ),\n  winner = case_when(\n    democrat &gt; republican ~ \"democrat\",\n    democrat &lt; republican ~ \"republican\",\n    .default = \"tie\")\n  )\n\nev_2012 &lt;- results_2012_df %&gt;% select(state, ev)\n\n\nintrade_combined &lt;- bind_rows(\n  mutate(intrade08, year = 2008),\n  mutate(intrade12, year = 2012)\n) %&gt;%\n  rename(\"date\" = \"day\",\n         \"state\" = \"statename\")\n\npolls_combined &lt;- bind_rows(\n  mutate(polls08, year = 2008),\n  mutate(polls12, year = 2012)\n) %&gt;%\n  mutate(scale = 100,\n         state = as.factor(state))\n\nelection_results_combined &lt;-\n  bind_rows(results_2008_df %&gt;%\n              filter(state != \"U.S. Total\") %&gt;%\n              mutate(year = 2008), \n            results_2012_df %&gt;%\n              filter(state != \"U.S. Total\") %&gt;%\n              mutate(year = 2012)) %&gt;%\n  mutate(dem_ev = ifelse(winner == \"democrat\", as.numeric(ev), 0),\n         rep_ev = ifelse(winner == \"republican\", as.numeric(ev), 0))\n\nintrade_combined_election_eve_08 &lt;-\n  intrade_combined %&gt;%\n  filter((year == 2008 & date &lt;= \"2008-11-03\") #|\n         #(year == 2012 & date == \"2012-11-05\")\n  ) %&gt;%\n  #filter(!is.na(democrat) & !is.na(republican)) %&gt;%\n  group_by(state) %&gt;%\n  slice_max(date) %&gt;%\n  left_join(results_2008_df %&gt;% select(state, winner), by = \"state\") %&gt;%\n  rename(\"actual_winner\"=\"winner\") %&gt;%\n  mutate(color = ifelse(actual_winner == pred_winner, \"#00BA38\", \"#F8766D\")) %&gt;%\n  ungroup()\n\n\nintrade_combined_election_eve_12 &lt;-\n  intrade_combined %&gt;%\n  filter((year == 2012 & date &lt;= \"2012-11-05\") #|\n         #(year == 2012 & date == \"2012-11-05\")\n  ) %&gt;%\n  #filter(!is.na(democrat) & !is.na(republican)) %&gt;%\n  group_by(state) %&gt;%\n  slice_max(date) %&gt;%\n  left_join(results_2012_df %&gt;% select(state, winner), by = \"state\") %&gt;%\n  rename(\"actual_winner\"=\"winner\") %&gt;%\n  mutate(color = ifelse(actual_winner == pred_winner, \"#00BA38\", \"#F8766D\")) %&gt;%\n  ungroup()\n\n\n\npolls_combined_election_eve_08 &lt;-\n  polls_combined %&gt;%\n  filter((year == 2008 & date &lt;= \"2008-11-03\")) %&gt;%\n  group_by(state, date, year) %&gt;%\n  summarise(democrat_avg = mean(democrat),\n            republican_avg = mean(republican)) %&gt;%\n  ungroup() %&gt;%\n  group_by(state) %&gt;%\n  slice_max(date) %&gt;%\n  mutate(pred_winner = case_when(\n    democrat_avg &gt; republican_avg ~ \"democrat\",\n    republican_avg &gt; democrat_avg ~ \"republican\",\n    .default = \"Tie\"\n  )) %&gt;%\n  left_join(results_2008_df %&gt;% select(state, winner), by = \"state\") %&gt;%\n  rename(\"actual_winner\"=\"winner\") %&gt;%\n  mutate(color = ifelse(actual_winner == pred_winner, \"#00BA38\", \"#F8766D\"))\n\npolls_combined_election_eve_12 &lt;-\n  polls_combined %&gt;%\n  filter((year == 2012 & date &lt;= \"2012-11-05\")) %&gt;%\n  group_by(state, date, year) %&gt;%\n  summarise(democrat_avg = mean(democrat),\n            republican_avg = mean(republican)) %&gt;%\n  ungroup() %&gt;%\n  group_by(state) %&gt;%\n  slice_max(date) %&gt;%\n  mutate(pred_winner = case_when(\n    democrat_avg &gt; republican_avg ~ \"democrat\",\n    republican_avg &gt; democrat_avg ~ \"republican\",\n    .default = \"Tie\"\n  )) %&gt;%\n  left_join(results_2012_df %&gt;% select(state, winner), by = \"state\") %&gt;%\n  rename(\"actual_winner\"=\"winner\") %&gt;%\n  mutate(color = ifelse(actual_winner == pred_winner, \"#00BA38\", \"#F8766D\"))\n\npolls_eve_combined_08_12 &lt;-\n  bind_rows(polls_combined_election_eve_08, polls_combined_election_eve_12)\n\n# used for finding only states in common between all data sets\n# for plotting electoral votes fairly\nall_states_list &lt;-\n  inner_join(election_results_combined, \n             intrade_combined_election_eve_08, \n             polls_combined_election_eve_08, \n             by = \"state\") %&gt;%\n  distinct(state) %&gt;%\n  pull()"
  },
  {
    "objectID": "posts/blog_post_04/index.html#introduction",
    "href": "posts/blog_post_04/index.html#introduction",
    "title": "Blog Post 04",
    "section": "",
    "text": "In this blog post, I analayze whether prediction markets are a better way to gauge public support for candidates than traditional polls. This analysis uses three data sources from the 2008 election cycle. The first being data from Intrade, a former Irish web-based trading exchange, sourced from Kosuke Imai (Harvard University)’s GitHub repository. Intrade operated as a prediction market where members traded contracts on the likelihood of certain events occurring. Their contracts are on a point scale of 0 to 100 points where a contract with a value of 0 suggests a given event will not occur. Intrade contracts offer an interpretation of the global market’s opinion on the probability of a particular presidential candidate winning. Variables from this data set included the date, state name, state abbreviation, price of democrat candidate’s contract, price of a republican candidate’s contract the volume of traders of democrat contracts, and volume of traders of republican contracts. The second data set used was polling data also sourced from Kosuke Imai’s github repository, that contained over 400 pollsters worth of polling data for US states. The last data set consisted of election outcome data from the 2008 and 2012 election cycles that was scraped from Wikipedia. This data included the percent of votes, number of votes, and electoral votes won by each candidate in the respective elections.\n\n## Load packages\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(plotly)\nlibrary(rvest)\nlibrary(maps)\nlibrary(tigris)\nlibrary(mapview)\nlibrary(sf)\nlibrary(usmap)\nlibrary(leaflet)\nlibrary(leafpop)\n\n\n## Data cleaning\nstate_df &lt;- ggplot2::map_data(\"state\")\n\nus_geo &lt;- tigris::states(cb = TRUE, resolution = '20m')\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======                                                                |   9%\n  |                                                                            \n  |========================                                              |  35%\n  |                                                                            \n  |===============================                                       |  44%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |===========================================                           |  61%\n  |                                                                            \n  |=================================================                     |  70%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |======================================================================| 100%\n\nstates_df &lt;- \n  tibble(state = state.name) %&gt;%\n  bind_cols(tibble(abb = state.abb)) %&gt;% \n  bind_rows(tibble(state = \"District of Columbia\", abb = \"DC\"))\n\nintrade08 &lt;- read_csv(\"https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/intrade08.csv\") %&gt;%\n  select(2:7) %&gt;%\n  mutate(PriceD = ifelse(is.na(PriceD), 0, PriceD),\n         PriceR = ifelse(is.na(PriceR), 0, PriceR)) %&gt;%\n  mutate(statename = as.factor(statename),\n         democrat_candidate = \"Barack Obama\",\n         republican_candidate = \"John McCain\",\n         pred_winner = case_when(\n           PriceD &gt; PriceR ~ \"democrat\",\n           PriceR &gt; PriceD ~ \"republican\",\n           .default = \"Tie\"\n         )\n  ) %&gt;%\n  rename(#\"state\" = \"statename\",\n    \"democrat\" = \"PriceD\",\n    \"republican\" = \"PriceR\") %&gt;%\n  filter(day &lt; as.Date(\"2008-11-04\"))\n\nintrade12 &lt;- read_csv(\"https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/intrade12.csv\") %&gt;%\n  select(2:7) %&gt;%\n  mutate(PriceD = ifelse(is.na(PriceD), 0, PriceD),\n         PriceR = ifelse(is.na(PriceR), 0, PriceR)) %&gt;%\n  mutate(statename = as.factor(statename),\n         democrat_candidate = \"Barack Obama\",\n         republican_candidate = \"Mitt Romney\",\n         pred_winner = case_when(\n           PriceD &gt; PriceR ~ \"democrat\",\n           PriceR &gt; PriceD ~ \"republican\",\n           .default = \"Tie\"\n         )\n  )%&gt;%\n  rename(#\"state\" = \"statename\",\n    \"democrat\" = \"PriceD\",\n    \"republican\" = \"PriceR\") %&gt;%\n  filter(day &lt; as.Date(\"2012-11-06\"))\n\npolls08 &lt;- read_csv(\"https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/polls08.csv\") %&gt;%\n  rename(\"statename\" = \"state\") %&gt;%\n  mutate(statename = as.factor(statename), \n         democrat_candidate = \"Barack Obama\",\n         republican_candidate = \"John McCain\") %&gt;%\n  left_join(states_df, by = c(\"statename\" = \"abb\")) %&gt;%\n  rename(\"democrat\" = \"Obama\",\n         \"republican\" = \"McCain\",\n         \"date\" = \"middate\") %&gt;%\n  mutate(pred_winner = case_when(\n    democrat &gt; republican ~ \"democrat\",\n    republican &gt; democrat ~ \"republican\",\n    .default = \"Tie\"\n  )) %&gt;%\n  select(-statename) %&gt;%\n  select(state, everything())\n\npolls12 &lt;- read_csv(\"https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/polls12.csv\") %&gt;%\n  select(2:6) %&gt;%\n  rename(\"statename\" = \"state\") %&gt;%\n  mutate(statename = as.factor(statename), \n         democrat_candidate = \"Barack Obama\",\n         republican_candidate = \"Mitt Romney\") %&gt;%\n  left_join(states_df, by = c(\"statename\" = \"abb\")) %&gt;%\n  rename(\"democrat\" = \"Obama\",\n         \"republican\" = \"Romney\",\n         \"date\" = \"middate\") %&gt;%\n  mutate(pred_winner = case_when(\n    democrat &gt; republican ~ \"democrat\",\n    republican &gt; democrat ~ \"republican\",\n    .default = \"Tie\"\n  )) %&gt;%\n  select(-statename) %&gt;%\n  select(state, everything())\n\n\n## '08 election\n`2008_results_scrape` &lt;- read_html(\"https://en.wikipedia.org/wiki/2008_United_States_presidential_election\")\n\n`2008_election_tables` &lt;- `2008_results_scrape` %&gt;% html_nodes(\"table.wikitable\")\n\n`2008_results_table` &lt;- `2008_election_tables`[[10]]\n\n`2008_results_df` &lt;- \n  `2008_results_table` %&gt;% \n  html_table(header = T) \n\nnew_names &lt;- c(\"Column1\", \n               \"Column2\", \n               \"Barack_Obama_Democratic\", \n               \"Barack_Obama_Democratic\",\n               \"Barack_Obama_EV\", \n               \"John_McCain_Republican\", \n               \"John_McCain_Republican\",\n               \"John_McCain_EV\", \n               \"Ralph_Nader_Independent\", \n               \"Ralph_Nader_Independent\",\n               \"Ralph_Nader_Independent\", \n               \"Bob_Barr_Libertarian\", \n               \"Bob_Barr_Libertarian\",\n               \"Bob_Barr_Libertarian\", \n               \"Chuck_Baldwin_Constitution\", \n               \"Chuck_Baldwin_Constitution\",\n               \"Chuck_Baldwin_Constitution\", \n               \"Cynthia_McKinney_Green\", \n               \"Cynthia_McKinney_Green\",\n               \"Cynthia_McKinney_Green\", \n               \"Others\",\"Others\",\"Others\", \n               \"Margin\", \"Margin\",\n               \"Total_votes\", \"Total_votes\")\n\n\n# Rename the nameless columns\nnames(`2008_results_df`)[names(`2008_results_df`) == \"\"] &lt;- new_names\n\nresults_2008_df &lt;-\n  `2008_results_df` %&gt;%\n  select(1,2,4,7,26) %&gt;%\n  rename(\"state\" = \"Column1\",\n         \"ev\" = \"Column2\",\n         \"democrat\" = \"Barack ObamaDemocratic\",\n         \"republican\" = \"John McCainRepublican\",\n         \"votes\" = \"Total votes\") %&gt;%\n  slice(-1) %&gt;%\n  mutate(votes = as.numeric(str_replace_all(votes, \",\", \"\")),\n         democrat = as.numeric(str_replace_all(democrat, \"%\", \"\")),\n         republican = as.numeric(str_replace_all(republican, \"%\", \"\")),\n         state = as.factor(state)) %&gt;%\n  mutate(state = case_when(\n    state == \"Nebraska†\" ~ \"Nebraska\",\n    state == \"Maine†\" ~ \"Maine\",\n    .default = state\n  ),\n  winner = case_when(\n    democrat &gt; republican ~ \"democrat\",\n    democrat &lt; republican ~ \"republican\",\n    .default = \"tie\")\n  )\n\nev_2008 &lt;- results_2008_df %&gt;% select(state, ev)\n\n\n\n## '12 Election\n`2012_results_scrape` &lt;- read_html(\"https://en.wikipedia.org/wiki/2012_United_States_presidential_election\")\n\n`2012_election_tables` &lt;- `2012_results_scrape` %&gt;% html_nodes(\"table.wikitable\")\n\n`2012_results_table` &lt;- `2012_election_tables`[[8]]\n\n`2012_results_df` &lt;- \n  `2012_results_table` %&gt;% \n  html_table(header = T) \n\nnames(`2012_results_df`)[4] &lt;- \"Obama_EV\"\nnames(`2012_results_df`)[7] &lt;- \"Romney_EV\"\n\n`2012_results_df` &lt;-\n  `2012_results_df` %&gt;%\n  select(1,3,4,6,7,19) %&gt;%\n  mutate(ev = ifelse(Obama_EV == \"–\", Romney_EV, Obama_EV)) %&gt;%\n  select(1,2,4,6,7)\n\n\nnew_names &lt;- c(\"state\", \"democrat\", \n               \"republican\", \"votes\")\n\n# Rename the nameless columns\nnames(`2012_results_df`)[names(`2012_results_df`) == \"\"] &lt;- new_names\n\nresults_2012_df &lt;-\n  `2012_results_df` %&gt;%\n  rename(\"state\" = \"State/District\",\n         \"democrat\" = \"Barack ObamaDemocratic\",\n         \"republican\" = \"Mitt RomneyRepublican\",\n         \"votes\" = \"Total\") %&gt;%\n  slice(-1) %&gt;%\n  mutate(votes = as.numeric(str_replace_all(votes, \",\", \"\")),\n         democrat = as.numeric(str_replace_all(democrat, \"%\", \"\")),\n         republican = as.numeric(str_replace_all(republican, \"%\", \"\")),\n         state = as.factor(state)) %&gt;%\n  filter(state != \"ME-1Tooltip Maine's 1st congressional district\" &\n           state != \"ME-2Tooltip Maine's 2nd congressional district\" &\n           state != \"NE-1Tooltip Nebraska's 1st congressional district\") %&gt;%\n  mutate(state = case_when(\n    state == \"Nebraska†\" ~ \"Nebraska\",\n    state == \"Maine†\" ~ \"Maine\",\n    state == \"District of ColumbiaDistrict of Columbia\" ~ \"District of Columbia\",\n    state == \"New Jersey[121]\" ~ \"New Jersey\",\n    state == \"New York[122]\" ~ \"New York\",\n    state == \"Ohio[123]\" ~ \"Ohio\",\n    state == \"Wisconsin[124]\" ~ \"Wisconsin\",\n    .default = state\n  ),\n  winner = case_when(\n    democrat &gt; republican ~ \"democrat\",\n    democrat &lt; republican ~ \"republican\",\n    .default = \"tie\")\n  )\n\nev_2012 &lt;- results_2012_df %&gt;% select(state, ev)\n\n\nintrade_combined &lt;- bind_rows(\n  mutate(intrade08, year = 2008),\n  mutate(intrade12, year = 2012)\n) %&gt;%\n  rename(\"date\" = \"day\",\n         \"state\" = \"statename\")\n\npolls_combined &lt;- bind_rows(\n  mutate(polls08, year = 2008),\n  mutate(polls12, year = 2012)\n) %&gt;%\n  mutate(scale = 100,\n         state = as.factor(state))\n\nelection_results_combined &lt;-\n  bind_rows(results_2008_df %&gt;%\n              filter(state != \"U.S. Total\") %&gt;%\n              mutate(year = 2008), \n            results_2012_df %&gt;%\n              filter(state != \"U.S. Total\") %&gt;%\n              mutate(year = 2012)) %&gt;%\n  mutate(dem_ev = ifelse(winner == \"democrat\", as.numeric(ev), 0),\n         rep_ev = ifelse(winner == \"republican\", as.numeric(ev), 0))\n\nintrade_combined_election_eve_08 &lt;-\n  intrade_combined %&gt;%\n  filter((year == 2008 & date &lt;= \"2008-11-03\") #|\n         #(year == 2012 & date == \"2012-11-05\")\n  ) %&gt;%\n  #filter(!is.na(democrat) & !is.na(republican)) %&gt;%\n  group_by(state) %&gt;%\n  slice_max(date) %&gt;%\n  left_join(results_2008_df %&gt;% select(state, winner), by = \"state\") %&gt;%\n  rename(\"actual_winner\"=\"winner\") %&gt;%\n  mutate(color = ifelse(actual_winner == pred_winner, \"#00BA38\", \"#F8766D\")) %&gt;%\n  ungroup()\n\n\nintrade_combined_election_eve_12 &lt;-\n  intrade_combined %&gt;%\n  filter((year == 2012 & date &lt;= \"2012-11-05\") #|\n         #(year == 2012 & date == \"2012-11-05\")\n  ) %&gt;%\n  #filter(!is.na(democrat) & !is.na(republican)) %&gt;%\n  group_by(state) %&gt;%\n  slice_max(date) %&gt;%\n  left_join(results_2012_df %&gt;% select(state, winner), by = \"state\") %&gt;%\n  rename(\"actual_winner\"=\"winner\") %&gt;%\n  mutate(color = ifelse(actual_winner == pred_winner, \"#00BA38\", \"#F8766D\")) %&gt;%\n  ungroup()\n\n\n\npolls_combined_election_eve_08 &lt;-\n  polls_combined %&gt;%\n  filter((year == 2008 & date &lt;= \"2008-11-03\")) %&gt;%\n  group_by(state, date, year) %&gt;%\n  summarise(democrat_avg = mean(democrat),\n            republican_avg = mean(republican)) %&gt;%\n  ungroup() %&gt;%\n  group_by(state) %&gt;%\n  slice_max(date) %&gt;%\n  mutate(pred_winner = case_when(\n    democrat_avg &gt; republican_avg ~ \"democrat\",\n    republican_avg &gt; democrat_avg ~ \"republican\",\n    .default = \"Tie\"\n  )) %&gt;%\n  left_join(results_2008_df %&gt;% select(state, winner), by = \"state\") %&gt;%\n  rename(\"actual_winner\"=\"winner\") %&gt;%\n  mutate(color = ifelse(actual_winner == pred_winner, \"#00BA38\", \"#F8766D\"))\n\npolls_combined_election_eve_12 &lt;-\n  polls_combined %&gt;%\n  filter((year == 2012 & date &lt;= \"2012-11-05\")) %&gt;%\n  group_by(state, date, year) %&gt;%\n  summarise(democrat_avg = mean(democrat),\n            republican_avg = mean(republican)) %&gt;%\n  ungroup() %&gt;%\n  group_by(state) %&gt;%\n  slice_max(date) %&gt;%\n  mutate(pred_winner = case_when(\n    democrat_avg &gt; republican_avg ~ \"democrat\",\n    republican_avg &gt; democrat_avg ~ \"republican\",\n    .default = \"Tie\"\n  )) %&gt;%\n  left_join(results_2012_df %&gt;% select(state, winner), by = \"state\") %&gt;%\n  rename(\"actual_winner\"=\"winner\") %&gt;%\n  mutate(color = ifelse(actual_winner == pred_winner, \"#00BA38\", \"#F8766D\"))\n\npolls_eve_combined_08_12 &lt;-\n  bind_rows(polls_combined_election_eve_08, polls_combined_election_eve_12)\n\n# used for finding only states in common between all data sets\n# for plotting electoral votes fairly\nall_states_list &lt;-\n  inner_join(election_results_combined, \n             intrade_combined_election_eve_08, \n             polls_combined_election_eve_08, \n             by = \"state\") %&gt;%\n  distinct(state) %&gt;%\n  pull()"
  },
  {
    "objectID": "posts/blog_post_04/index.html#visualizations",
    "href": "posts/blog_post_04/index.html#visualizations",
    "title": "Blog Post 04",
    "section": "Visualizations",
    "text": "Visualizations\n\n\n\n\n## Electoral votes on election-eve 2008\nintrade_08_ev &lt;-\n  intrade_combined_election_eve_08 %&gt;%\n  filter(state %in% all_states_list) %&gt;%\n  left_join(ev_2008, by = \"state\") %&gt;%\n  mutate(na_ev = as.numeric(ifelse(pred_winner == \"Tie\", ev, 0)),\n         dem_ev = as.numeric(ifelse(pred_winner == \"democrat\", ev, 0)),\n         rep_ev = as.numeric(ifelse(pred_winner == \"republican\", ev, 0))) %&gt;%\n  group_by(year) %&gt;%\n  summarise(dem_ev_sum = sum(dem_ev),\n            rep_ev_sum = sum(rep_ev),\n            na_ev_sum = sum(na_ev)) %&gt;%\n  rename(\"Democrat\" = \"dem_ev_sum\",\n         \"Republican\" = \"rep_ev_sum\",\n         \"NA\" = \"na_ev_sum\",\n         \"Year\" = \"year\") %&gt;%\n  pivot_longer(cols = c(\"Democrat\",\"Republican\",\"NA\"), \n               values_to = \"electoral_votes\", \n               names_to = \"Party\") %&gt;%\n  mutate(Year = as.factor(Year))\n\npolls_o8_ev &lt;-\n  polls_combined_election_eve_08 %&gt;%\n  filter(state %in% all_states_list) %&gt;%\n  left_join(ev_2008, by = \"state\") %&gt;%\n  mutate(na_ev = as.numeric(ifelse(pred_winner == \"Tie\", ev, 0)),\n         dem_ev = as.numeric(ifelse(pred_winner == \"democrat\", ev, 0)),\n         rep_ev = as.numeric(ifelse(pred_winner == \"republican\", ev, 0))) %&gt;%\n  group_by(year) %&gt;%\n  summarise(dem_ev_sum = sum(dem_ev),\n            rep_ev_sum = sum(rep_ev),\n            na_ev_sum = sum(na_ev)) %&gt;%\n  rename(\"Democrat\" = \"dem_ev_sum\",\n         \"Republican\" = \"rep_ev_sum\",\n         \"NA\" = \"na_ev_sum\",\n         \"Year\" = \"year\") %&gt;%\n  pivot_longer(cols = c(\"Democrat\",\"Republican\",\"NA\"), \n               values_to = \"electoral_votes\", \n               names_to = \"Party\") %&gt;%\n  mutate(Year = as.factor(Year))\n\n\nsummary_results_ev &lt;-\n  election_results_combined %&gt;%\n  filter(state %in% all_states_list) %&gt;%\n  group_by(year) %&gt;%\n  summarise(dem_ev_sum = sum(dem_ev),\n            rep_ev_sum = sum(rep_ev)) %&gt;%\n  rename(\"Democrat\" = \"dem_ev_sum\",\n         \"Republican\" = \"rep_ev_sum\",\n         \"Year\" = \"year\") %&gt;%\n  pivot_longer(cols = c(\"Democrat\",\"Republican\"), \n               values_to = \"electoral_votes\", \n               names_to = \"Party\") %&gt;%\n  mutate(Year = as.factor(Year))\n\nmiddle_val &lt;- \n  summary_results_ev %&gt;%\n  filter(Year == 2008) %&gt;%\n  summarise(middle_val = sum(electoral_votes)/2) %&gt;%\n  pull()\n\n\nstacked_df &lt;-\n  bind_rows(summary_results_ev %&gt;%\n              mutate(Source = \"Official Election Results\"), \n            intrade_08_ev %&gt;%\n              mutate(Source = \"Betting Predicted Results\"),\n            polls_o8_ev %&gt;%\n              mutate(Source = \"Poll Predicted Results\")) %&gt;%\n  mutate(Party = fct_relevel(Party, \"Republican\", \"NA\",\"Democrat\"),\n         source = as.factor(Source),\n         Source = fct_relevel(Source, \n                              \"Official Election Results\", \n                              \"Betting Predicted Results\",\n                              \"Poll Predicted Results\")) %&gt;%\n  filter(Year == 2008) %&gt;%\n  group_by(Source) %&gt;%\n  ungroup()\n\nelectoral_results &lt;-\n  ggplot(stacked_df,\n         aes(x = Source, \n             y = electoral_votes, \n             fill = Party)) +\n  geom_histogram(position = \"stack\", stat = \"identity\") +\n  scale_fill_manual(values = c(\"Republican\" = \"#E81B23\",\n                               \"Democrat\" = \"#00AEF3\",\n                               \"NA\"=\"grey\")) +\n    labs(title = \"2008 Election Electoral Votes\") +\n    geom_hline(yintercept = middle_val, colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n    coord_flip() +\n    theme_minimal() +\n    theme(plot.title = element_text(hjust = 0.5))\n\nplotly::ggplotly(electoral_results)\n\n\n\n\n\n\n\n\n\n\n\nHere it can be seen the Intrade prediction market outperformed the conventional pollsters by 15 electoral votes. In fact, Intrade forecasted the exact electoral college outcome on election-eve of 2008 (November 3rd, 2008). To get a better sense of the election break down, next we will analyze a choropleth map of state classifications below.\n\n\n\n\n\n\n\n\n## Intrade Election-eve Classification Map\nintrade_classification_data &lt;-\n  intrade_combined %&gt;%\n  filter((year == 2008 & date &lt;= as.Date(\"2008-11-03\"))) %&gt;%\n  group_by(state, date, year) %&gt;%\n  summarise(democrat_avg = mean(democrat),\n            republican_avg = mean(republican)) %&gt;%\n  ungroup() %&gt;%\n  group_by(state) %&gt;%\n  slice_max(date) %&gt;%\n  mutate(pred_winner = case_when(\n    democrat_avg &gt; republican_avg ~ \"democrat\",\n    republican_avg &gt; democrat_avg ~ \"republican\",\n    .default = \"Tie\"\n  )) %&gt;%\n  left_join(results_2008_df %&gt;% select(state, winner), by = \"state\") %&gt;%\n  rename(\"actual_winner\"=\"winner\") %&gt;%\n  mutate(color = as.factor(case_when(\n    pred_winner == \"Tie\" ~ \"Tie\",\n    actual_winner == pred_winner ~ \"Correct\", \n    .default = \"Incorrect\")\n  )) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'state', 'date'. You can override using the\n`.groups` argument.\n\nintrade_classification_data$color &lt;- \n  fct_relevel(intrade_classification_data$color, \"Correct\", \"Incorrect\", \"Tie\")\n\nWarning: 1 unknown level in `f`: Tie\n\nintrade_classification_data &lt;- \n  inner_join(us_geo, intrade_classification_data, by = c(\"NAME\" = \"state\"))\n\n\nintrade_map_08 &lt;-\nmapview(intrade_classification_data, zcol = \"color\", color = \"white\", \n        col.regions = c(\"seagreen3\", \"red\"),\n        label = glue::glue(\"{intrade_classification_data$NAME}\"),\n        popup = popupTable(intrade_classification_data, \n                           zcol = c(\"NAME\",\n                                    \"date\", \n                                    \"democrat_avg\", \n                                    \"republican_avg\", \n                                    \"pred_winner\", \n                                    \"actual_winner\",\n                                    \"color\"),\n                           feature.id = F, \n                           row.numbers = F)\n)\n\n\n\n\n\n\n2008 Intrade Markets Classifications\n\n\n\n\n\n\n\n\nintrade_map_08\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Poll election-eve classification map\npoll_classification_data_08 &lt;-\n  polls_combined %&gt;%\n  filter((year == 2008 & date &lt;= as.Date(\"2008-11-03\"))) %&gt;%\n  group_by(state, date, year) %&gt;%\n  summarise(democrat_avg = mean(democrat),\n            republican_avg = mean(republican)) %&gt;%\n  ungroup() %&gt;%\n  group_by(state) %&gt;%\n  slice_max(date) %&gt;%\n  mutate(pred_winner = case_when(\n    democrat_avg &gt; republican_avg ~ \"democrat\",\n    republican_avg &gt; democrat_avg ~ \"republican\",\n    .default = \"Tie\"\n  )) %&gt;%\n  left_join(results_2008_df %&gt;% select(state, winner), by = \"state\") %&gt;%\n  rename(\"actual_winner\"=\"winner\") %&gt;%\n  mutate(color = as.factor(case_when(\n    pred_winner == \"Tie\" ~ \"Tie\",\n    actual_winner == pred_winner ~ \"Correct\", \n    .default = \"Incorrect\")\n  )) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'state', 'date'. You can override using the\n`.groups` argument.\n\npoll_classification_data_08$color &lt;- \n  fct_relevel(poll_classification_data_08$color, \"Correct\", \"Incorrect\", \"Tie\")\n\npoll_classification_data_08 &lt;- \n  inner_join(us_geo, poll_classification_data_08, by = c(\"NAME\" = \"state\"))\n\n\npolls_map_08 &lt;-\n  mapview(poll_classification_data_08, zcol = \"color\", color = \"white\", \n          col.regions = c(\"seagreen3\", \"red\"),\n          label = glue::glue(\"{poll_classification_data_08$NAME}\"),\n          popup = popupTable(poll_classification_data_08, \n                             zcol = c(\"NAME\",\n                                      \"date\", \n                                      \"democrat_avg\", \n                                      \"republican_avg\", \n                                      \"pred_winner\", \n                                      \"actual_winner\",\n                                      \"color\"),\n                             feature.id = F, \n                             row.numbers = F)\n  )\n\n\n\n\n\n2008 Polling Classifications\n\n\n\n\n\n\n\npolls_map_08\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOn election-eve of 2008, both the pollsters and the Intrade prediction market wrongly predicted Indiana and Missouri nominating John McCain and Barack Obama, respectively. Intrade was able to achieve a perfect electoral vote total because both Missouri and Indiana have 11 electoral votes, so misclassifying the two states had no effect on the total electoral outcome. Additionally, the polls misclassified North Carolina, predicting McCain as the winner.\n\n\n\n\n\n## NC 2008 Time Series Betting\nnc_08_betting &lt;-\n  probabilities &lt;-\n  intrade_combined %&gt;%\n  filter(year == 2008) %&gt;%\n  filter(date &gt;= as.Date(\"2008-01-01\")) %&gt;%\n  filter(state == \"North Carolina\") %&gt;%\n  filter(democrat + republican &gt; 30) %&gt;%\n  group_by(date) %&gt;%\n  summarise(Democrat = round(mean(democrat, na.rm = T), digits = 2),\n            Republican = round(mean(republican, na.rm = T), digits = 2)) %&gt;%\n  ungroup() %&gt;%\n  rename(\"Date\" = \"date\") %&gt;%\n  ggplot(aes(x = Date,\n             y = Democrat)\n  ) +\n  geom_line(aes(x = Date, \n                y = Democrat),\n            colour = \"#00AEF3\") +\n  geom_hline(yintercept = 50, colour = \"black\") +\n  geom_line(aes(x = Date, \n                y = Republican),\n            colour = \"#E81B23\") +\n  \n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-01-03\")),\n                 text = paste0(\"Obama Wins Iowa Democratic Caucus\\n\",\n                               \"Date: 2008-01-03\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-02-05\")),\n                 text = paste0(\"2008 Super Tuesday\\n\",\n                               \"Date: 2008-02-05\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-09-15\")),\n                 text = paste0(\"Lehman Brothers File for Bankruptcy\\n\",\n                               \"Date: 2008-09-15\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-09-06\")),\n                 text = paste0(\"Fannie Mae and Freddie Mac Seized\\n\",\n                               \"Date: 2008-09-06\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-08-29\")),\n                 text = paste0(\"McCain Announces Palin as VP\\n\",\n                               \"Date: 2008-08-29\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-08-27\")),\n                 text = paste0(\"Obama Wins Nomination\\nAnnounces Biden as VP\\n\",\n                               \"Date: 2008-08-27\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-11-04\")),\n                 text = paste0(\"2008 Election Day\\n\",\n                               \"Date: 2008-11-04\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-08-11\")),\n                 text = paste0(\"2012 Iowa Caucuses\\n\",\n                               \"Date: 2012-08-11\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-03-06\")),\n                 text = paste0(\"Super Tuesday 2012\\n\",\n                               \"Date: 2012-03-06\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-04-25\")),\n                 text = paste0(\"RNC Declares Romney as Republican Nominee\\n\",\n                               \"Date: 2012-04-25\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-08-11\")),\n                 text = paste0(\"Mitt Romney Announces Paul Ryan as VP\\n\",\n                               \"Date: 2012-08-11\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-10-29\")),\n                 text = paste0(\"Hurricane Sandy\\n\",\n                               \"Date: 2012-10-29\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-11-06\")),\n                 text = paste0(\"2012 Election Day\\n\",\n                               \"Date: 2012-11-06\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  scale_y_continuous(limits = c(0,100)) +\n  labs(x = \"Date\",\n       y = \"Closing Price of Party Nominee's Market\",\n       title = \"2008 North Carolina Intrade Contract Closing Prices\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\nnc_08_betting &lt;-\n  plotly::ggplotly(nc_08_betting,  \n                   tooltip = c(\"x\",\n                               \"y\",\n                               \"text\"))\n\n\nnc_08_polls &lt;-\n  probabilities &lt;-\n  polls_combined %&gt;%\n  filter(year == 2008) %&gt;%\n  filter(state == \"North Carolina\") %&gt;%\n  filter(date &gt;= as.Date(\"2008-01-01\")) %&gt;%\n  filter(democrat + republican &gt; 30) %&gt;%\n  group_by(date) %&gt;%\n  summarise(Democrat = round(mean(democrat, na.rm = T), digits = 2),\n            Republican = round(mean(republican, na.rm = T), digits = 2)) %&gt;%\n  ungroup() %&gt;%\n  rename(\"Date\" = \"date\") %&gt;%\n  ggplot(aes(x = Date,\n             y = Democrat)\n  ) +\n  geom_line(aes(x = Date, \n                y = Democrat),\n            colour = \"#00AEF3\") +\n  geom_hline(yintercept = 50, colour = \"black\") +\n  geom_line(aes(x = Date, \n                y = Republican),\n            colour = \"#E81B23\") +\n  \n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-01-03\")),\n                 text = paste0(\"Obama Wins Iowa Democratic Caucus\\n\",\n                               \"Date: 2008-01-03\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-02-05\")),\n                 text = paste0(\"2008 Super Tuesday\\n\",\n                               \"Date: 2008-02-05\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-09-15\")),\n                 text = paste0(\"Lehman Brothers File for Bankruptcy\\n\",\n                               \"Date: 2008-09-15\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-09-06\")),\n                 text = paste0(\"Fannie Mae and Freddie Mac Seized\\n\",\n                               \"Date: 2008-09-06\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-08-29\")),\n                 text = paste0(\"McCain Announces Palin as VP\\n\",\n                               \"Date: 2008-08-29\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-08-27\")),\n                 text = paste0(\"Obama Wins Nomination\\nAnnounces Biden as VP\\n\",\n                               \"Date: 2008-08-27\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2008-11-04\")),\n                 text = paste0(\"2008 Election Day\\n\",\n                               \"Date: 2008-11-04\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-08-11\")),\n                 text = paste0(\"2012 Iowa Caucuses\\n\",\n                               \"Date: 2012-08-11\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-03-06\")),\n                 text = paste0(\"Super Tuesday 2012\\n\",\n                               \"Date: 2012-03-06\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-04-25\")),\n                 text = paste0(\"RNC Declares Romney as Republican Nominee\\n\",\n                               \"Date: 2012-04-25\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-08-11\")),\n                 text = paste0(\"Mitt Romney Announces Paul Ryan as VP\\n\",\n                               \"Date: 2012-08-11\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-10-29\")),\n                 text = paste0(\"Hurricane Sandy\\n\",\n                               \"Date: 2012-10-29\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  geom_vline(aes(xintercept = as.numeric(as.Date(\"2012-11-06\")),\n                 text = paste0(\"2012 Election Day\\n\",\n                               \"Date: 2012-11-06\")), \n             colour = \"black\", linetype = \"dashed\", alpha = 0.8) +\n  scale_y_continuous(limits = c(0,100)) +\n  labs(x = \"Date\",\n       y = \"Closing Price of Party Nominee's Market\",\n       title = \"2008 Missouri Polling Support\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5))\n\nnc_08_polls &lt;-\n  plotly::ggplotly(nc_08_polls,  \n                   tooltip = c(\"x\",\n                               \"y\",\n                               \"text\"))\n\n\nnc_08_betting\n\n\n\n\nnc_08_polls\n\n\n\n\n\n\n\n\n\nThe time series data in the plots above portrays the discrepancy in predicted election outcomes in North Carolina between Intrade prediction markets and polling data. It can be seen above with the Intrade data, a sharp decline of support for John McCain occurs in September, marked by the second vertical line from the far-right on the plot. Interestingly, this decline in contract value coincides with the day Lehman Brothers filed for bankruptcy on September 15th, 2008. This event was a catalyst for the 2008 recession, representing the largest bankruptcy in US history, with $691 billion in assets held before its collapse. Its repercussions rippled through the US economy, causing international market turmoil and the downfall of numerous banks. Interestingly, this significant decline in contract value is not mirrored in the polling data. Instead, following the Lehman Brothers’ bankruptcy, polling in North Carolina narrowed between Obama and McCain."
  },
  {
    "objectID": "posts/blog_post_04/index.html#conclusion-and-wrap-up",
    "href": "posts/blog_post_04/index.html#conclusion-and-wrap-up",
    "title": "Blog Post 04",
    "section": "Conclusion and Wrap-Up",
    "text": "Conclusion and Wrap-Up\nThe visualizations compared Intrade’s prediction market and traditional polling data in the context of US presidential elections. Using line plots, overlaid with interactive historical event lines, revealed current events had a greater influence on contract values within the prediction market compared to polling support. Betting markets naturally react more rapidly to new information than polls, helping them accurately reflect real time public sentiment. However, to truly determine if betting markets outperform polls, additional data beyond one election cycle is needed. In the 2012 election for example, Intrade contract values diverged significantly in close races in swing states, demonstrating the necessity for more observations to assess the performance of these two methodologies."
  },
  {
    "objectID": "posts/blog_post_03/index.html",
    "href": "posts/blog_post_03/index.html",
    "title": "Blog Post 03",
    "section": "",
    "text": "In my third blog post, I will be analyzing a data set of previous loans to create a statistical model to predict the likelihood of loan default. I acquired this data from Kaggle, which the user sourced from https://www.coursera.org/projects/data-science-coding-challenge-loan-default-prediction. The data set includes 255,347 observations (loans), and 18 variables including LoanID, Age, Income, LoanAmount, CreditScore, MonthsEmployed, NumCreditLines, InterestRate, LoanTerm, DTIRatio (debt to income ratio), Education (highest level of education of borrower), EmploymentType (full-employment, part-time, self-eployed, unemployed), MaritalStatus (single, married, divorced), HasMortgage (yes or no), HasDependents (yes or no), LoanPurpose (home, auto, education, business, or other), HasCoSigner (yes or no), and the response vairable Default (a binary where 0 for no default and 1 for a default). I seek to create and visualize multiple models to determine the best model."
  },
  {
    "objectID": "posts/blog_post_03/index.html#introduction",
    "href": "posts/blog_post_03/index.html#introduction",
    "title": "Blog Post 03",
    "section": "",
    "text": "In my third blog post, I will be analyzing a data set of previous loans to create a statistical model to predict the likelihood of loan default. I acquired this data from Kaggle, which the user sourced from https://www.coursera.org/projects/data-science-coding-challenge-loan-default-prediction. The data set includes 255,347 observations (loans), and 18 variables including LoanID, Age, Income, LoanAmount, CreditScore, MonthsEmployed, NumCreditLines, InterestRate, LoanTerm, DTIRatio (debt to income ratio), Education (highest level of education of borrower), EmploymentType (full-employment, part-time, self-eployed, unemployed), MaritalStatus (single, married, divorced), HasMortgage (yes or no), HasDependents (yes or no), LoanPurpose (home, auto, education, business, or other), HasCoSigner (yes or no), and the response vairable Default (a binary where 0 for no default and 1 for a default). I seek to create and visualize multiple models to determine the best model."
  },
  {
    "objectID": "posts/blog_post_03/index.html#primary-visualizations",
    "href": "posts/blog_post_03/index.html#primary-visualizations",
    "title": "Blog Post 03",
    "section": "Primary Visualizations",
    "text": "Primary Visualizations\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(broom)\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nlibrary(corrplot)\n\ncorrplot 0.92 loaded\n\nlibrary(corrplot)\nlibrary(broom)\nlibrary(modelr)\n\n\nAttaching package: 'modelr'\n\nThe following object is masked from 'package:broom':\n\n    bootstrap\n\ndefault &lt;- read_csv('/Users/bensunshine/Documents/SLU_Senior_Year/SP24/data_334/ds334blog/data/Loan_default.csv') %&gt;%\n  select(-LoanID)\n\nRows: 255347 Columns: 18\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (8): LoanID, Education, EmploymentType, MaritalStatus, HasMortgage, Has...\ndbl (10): Age, Income, LoanAmount, CreditScore, MonthsEmployed, NumCreditLin...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n# create a correlation matrix\ncor_mat &lt;- cor(default %&gt;% select(-c('Education', 'EmploymentType', 'MaritalStatus',\n       'HasMortgage', 'HasDependents', 'LoanPurpose', 'HasCoSigner')))\n\ncorrplot(cor_mat, tl.srt = 45)\n\n\n\n\n\n\n\n\n\nFrom the correlation plot above, we can see some of the variables with the highest correlation with Default are Age, InterestRate, Income, MonthsEmployed, and LoanAmount respectively. In my modeling below, I will use some of these variables, as well as some other variables of interest including CreditScore and MaritalStatus.\n\n\ndefault_simple_mod &lt;- glm(Default ~ Age + CreditScore + MaritalStatus, data = default)\n\ndefault_int_mod &lt;- glm(Default ~ Age  + MaritalStatus+ MaritalStatus:Age + CreditScore, data = default)\n\ndefault_expanded_mod &lt;- glm(Default ~ Age + CreditScore + MaritalStatus + \n                              MaritalStatus:Age  + I(CreditScore^2), data = default)\n\n\nIn my models I attempt to predict the response variable, Default, using the same variables, but with different feature engineering techniques for each. In the first model, I use Age, CreditScore, and MaritalStatus to predict Default. In my second model I use the same variables, but include and interaction term between MaritalStatus and Age. I did this to account for the possibility that the relationship between Age and Default may differ for individuals with different marital statuses. In my last model, I include both the previous interaction term, as well as squaring the CreditScore variable. Including a quadratic term allows for flexibility in modeling the complexity of CreditScore.\n\n\nbind_rows(default_simple_mod %&gt;% tidy(), default_int_mod %&gt;% tidy(), default_expanded_mod %&gt;% tidy(),  .id = \"model\")\n\n# A tibble: 20 × 6\n   model term                          estimate    std.error statistic   p.value\n   &lt;chr&gt; &lt;chr&gt;                            &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 1     (Intercept)               0.321        0.00309        104.    0        \n 2 1     Age                      -0.00359      0.0000417      -86.1   0        \n 3 1     CreditScore              -0.0000691    0.00000393     -17.6   3.22e- 69\n 4 1     MaritalStatusMarried     -0.0213       0.00153        -13.9   3.39e- 44\n 5 1     MaritalStatusSingle      -0.00658      0.00153         -4.30  1.72e-  5\n 6 2     (Intercept)               0.331        0.00402         82.4   0        \n 7 2     Age                      -0.00382      0.0000723      -52.8   0        \n 8 2     MaritalStatusMarried     -0.0498       0.00470        -10.6   3.47e- 26\n 9 2     MaritalStatusSingle      -0.00853      0.00469         -1.82  6.91e-  2\n10 2     CreditScore              -0.0000691    0.00000393     -17.6   2.90e- 69\n11 2     Age:MaritalStatusMarried  0.000653     0.000102         6.40  1.59e- 10\n12 2     Age:MaritalStatusSingle   0.0000446    0.000102         0.437 6.62e-  1\n13 3     (Intercept)               0.340        0.00934         36.3   1.85e-288\n14 3     Age                      -0.00382      0.0000723      -52.8   0        \n15 3     CreditScore              -0.000101     0.0000320       -3.14  1.67e-  3\n16 3     MaritalStatusMarried     -0.0498       0.00470        -10.6   3.41e- 26\n17 3     MaritalStatusSingle      -0.00854      0.00469         -1.82  6.90e-  2\n18 3     I(CreditScore^2)          0.0000000274 0.0000000277     0.991 3.22e-  1\n19 3     Age:MaritalStatusMarried  0.000653     0.000102         6.40  1.59e- 10\n20 3     Age:MaritalStatusSingle   0.0000446    0.000102         0.437 6.62e-  1\n\n\n\nIn all of the models, Age seems to be the most significant predictor with a p value near zero. For each additional one year increase in age holding all other predictors constant, on average the models predict the odds of default are the predicted odds of default of the previous year of age times 0.996. For the second model with the interaction term interestingly, the odds of default for each additional year of age of a married borrower are higher than that of a single borrower.\n\n\nsimple &lt;- default_simple_mod %&gt;% glance()\ninteraction &lt;- default_int_mod %&gt;% glance()\nexpand &lt;- default_expanded_mod %&gt;% glance()\n\nbind_rows(lst(simple, interaction, expand), .id = \"model\") %&gt;%\n  arrange(AIC) \n\n# A tibble: 3 × 9\n  model  null.deviance df.null  logLik    AIC    BIC deviance df.residual   nobs\n  &lt;chr&gt;          &lt;dbl&gt;   &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;int&gt;  &lt;int&gt;\n1 inter…        26209.  255346 -67745. 1.36e5 1.36e5   25415.      255340 255347\n2 expand        26209.  255346 -67744. 1.36e5 1.36e5   25415.      255339 255347\n3 simple        26209.  255346 -67771. 1.36e5 1.36e5   25421.      255342 255347\n\n\n\nUpon comparing these models, the second model, using just the interaction term, proved to be the best of the three due to its relatively lower AIC and BIC.\n\n\ngrid_simple &lt;- default |&gt;\n  data_grid(\n    CreditScore = seq_range(CreditScore, n= 2),\n    Age = seq_range(Age, n = 2),\n    MaritalStatus = c(\"Divorced\", \"Married\", \"Single\")\n    ) \n\n\ngrid_int &lt;- default |&gt;\n  data_grid(\n    Age = seq_range(Age, n = 2),\n    MaritalStatus = c(\"Divorced\", \"Married\", \"Single\"),\n    CreditScore = seq_range(CreditScore, n= 2)\n    ) \n\ngrid_expand &lt;- default |&gt;\n  data_grid(\n    Age = seq_range(Age, n = 2),\n    MaritalStatus = c(\"Divorced\", \"Married\", \"Single\"),\n    CreditScore = seq_range(CreditScore, n = 2)\n    ) \n\n\nmodel_simple &lt;- augment(default_simple_mod, newdata = grid_simple, interval = \"confidence\") %&gt;%\n  mutate(pred_prob = exp(.fitted)/(1+exp(.fitted)))\nmodel_int &lt;- augment(default_int_mod, newdata = grid_int, interval = \"confidence\") %&gt;%\n  mutate(pred_prob = exp(.fitted)/(1+exp(.fitted)))\nmodel_expand &lt;- augment(default_expanded_mod, newdata = grid_expand, interval = \"confidence\") %&gt;%\n  mutate(pred_prob = exp(.fitted)/(1+exp(.fitted)))\n\nplot_df &lt;- bind_rows(lst(model_simple, model_int, model_expand), .id = \"model\")\n\n\nggplot(plot_df, \n       aes(x = CreditScore, y = pred_prob)) +\n  geom_line(aes(color = as.factor(model)), \n            linewidth = 1.5) +\n  facet_wrap(Age~MaritalStatus) + \n  labs(x = \"Credit Score\", y = \"Predicted Probability of Default\",\n       title = \"Comparing Models of Default Probability\",\n       color = \"Model\") +\n  theme(axis.title.x = element_text(hjust = 0.5)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nFrom the plot above, it can be seen the slope of each model despite the marital status or age is consistent. What varies is the y intercept for each. It can be seen the group at highest risk of loan default is young divorced borrowers with lower credit scores. The next group would be single young borrowers with lower credit scores. Interestingly, regardless of marital status, older borrowers with low credit scores have a predicted lower probability of default than young borrowers with excellent credit."
  },
  {
    "objectID": "posts/blog_post_03/index.html#conclusion-and-wrap-up",
    "href": "posts/blog_post_03/index.html#conclusion-and-wrap-up",
    "title": "Blog Post 03",
    "section": "Conclusion and Wrap-Up",
    "text": "Conclusion and Wrap-Up\nThe second model using the interaction term between MaritalStatus and Age proved to be the best model of the three having a relatively lower AIC and BIC. One thing I could have done to get greater variability between the models’ estimated coefficients would have been to include different variables for each model. This may have made my visualizations more interesting. To take this analysis a step further I would like to utilize more advanced machine learning algorithms. Other algorithms like support vector machines, random forests, and neural networks often offer more accurate results, but offer less interpretability."
  },
  {
    "objectID": "posts/blog_post_03/index.html#connections-to-class-ideas",
    "href": "posts/blog_post_03/index.html#connections-to-class-ideas",
    "title": "Blog Post 03",
    "section": "Connections to Class Ideas",
    "text": "Connections to Class Ideas\nI first created a correlation matrix to aid in feature selection for modeling. This allowed me to avoid multicolinearity for my later modeling. I then created three logistic regression models aimed at classifying whether a borrower’s loan would default or not. I first fit the logistic models using standard variables, as well as featured engineered variables with interaction terms and a squared term. I then compared the models and identified the second model with the interaction preformed the best due to its relatively lower AIC and BIC. Then, I followed a similar pipeline to what we completed in class by augmenting my models with grids of sample data to generate predictions. I then plotted these models and faceted each model by the borrowers marital status and age. Each model was represented by a line with a unique color corresponding to that specific model. Doing this allowed me to visualize the complex relationships between different variables in my models."
  },
  {
    "objectID": "posts/blog_post_02/index.html",
    "href": "posts/blog_post_02/index.html",
    "title": "Blog Post 02",
    "section": "",
    "text": "In my second blog post, I will be analyzing a data set of countries’ C02 emissions. I acquired this data from Kaggle which the user sourced from https://data.worldbank.org/ in 2018. The data set includes 266 observations (countries and regions), as well as each location’s metric tons of C02 emissions per capita for years between 1960-2018. This metric indicates a country’s carbon dioxide (CO2) emissions in relation to its population size. Meaning, it quantifies the amount of CO2 emissions produced by a country per person, which provides insight into the individual carbon footprints and overall environmental sustainability for a given region. I seek to visualize which countries in recent history have had the largest changes in CO2 emission per capita. It is important to note there are groups and regions which are used in this data set (e.g. Post-demographic dividend, Upper middle income, Europe & Central Asia, etc) which I exclude from some of my later analysis, because the data set does not outline which countries fall into these groups and regions."
  },
  {
    "objectID": "posts/blog_post_02/index.html#introduction",
    "href": "posts/blog_post_02/index.html#introduction",
    "title": "Blog Post 02",
    "section": "",
    "text": "In my second blog post, I will be analyzing a data set of countries’ C02 emissions. I acquired this data from Kaggle which the user sourced from https://data.worldbank.org/ in 2018. The data set includes 266 observations (countries and regions), as well as each location’s metric tons of C02 emissions per capita for years between 1960-2018. This metric indicates a country’s carbon dioxide (CO2) emissions in relation to its population size. Meaning, it quantifies the amount of CO2 emissions produced by a country per person, which provides insight into the individual carbon footprints and overall environmental sustainability for a given region. I seek to visualize which countries in recent history have had the largest changes in CO2 emission per capita. It is important to note there are groups and regions which are used in this data set (e.g. Post-demographic dividend, Upper middle income, Europe & Central Asia, etc) which I exclude from some of my later analysis, because the data set does not outline which countries fall into these groups and regions."
  },
  {
    "objectID": "posts/blog_post_02/index.html#data-wrangling",
    "href": "posts/blog_post_02/index.html#data-wrangling",
    "title": "Blog Post 02",
    "section": "Data Wrangling",
    "text": "Data Wrangling\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(maps)\n\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nworld_df &lt;- ggplot2::map_data(\"world\")\n\n\nemissions &lt;- read_csv('/Users/bensunshine/Documents/SLU_Senior_Year/SP24/data_334/ds334blog/data/CO2_Emissions_1960-2018.csv')\n\nRows: 266 Columns: 60\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Country Name\ndbl (59): 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nnrow(emissions)\n\n[1] 266\n\n\n\n#anti_join(emissions, world_df, by = c(`Country Name` = \"region\"))\n\nemissions_longer &lt;-\n  emissions %&gt;%\n  rename(\"country\" = `Country Name`) %&gt;%\n  mutate(country = ifelse(country == \"United States\", \"USA\", country),\n         country = ifelse(country == \"Russian Federation\", \"Russia\", country),\n         country = ifelse(country == \"Cote d'Ivoire\", \"Ivory Coast\", country),\n         country = ifelse(country == \"Congo, Dem. Rep.\", \"Democratic Republic of the Congo\", country),\n         country = ifelse(country == \"Egypt, Arab Rep.\", \"Egypt\", country),\n         country = ifelse(country == \"Venezuela, RB\", \"Venezuela\", country),\n         country = ifelse(country == \"Congo, Rep.\", \"Democratic Republic of the Congo\", country),\n         country = ifelse(country == \"Kyrgyz Republic\", \"Kyrgyzstan\", country),\n         country = ifelse(country == \"Lao PDR\", \"Laos\", country),\n         \n         recent_percent_increase = ifelse(!is.na(`2000`) | `2000`!= 0, (`2018`-`2000`)/`2000`, NA),\n         recent_percent_increase = ifelse(recent_percent_increase == Inf, NA, recent_percent_increase)\n        ) %&gt;%\n  pivot_longer(cols = 2:ncol(emissions), names_to = \"year\", values_to = \"metric_tons_pcapita\") \n\nemission_lat_long &lt;-\n  emissions_longer %&gt;%\n  left_join(world_df, by = c(\"country\" = \"region\"))\n\nWarning in left_join(., world_df, by = c(country = \"region\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\nlargest_inc &lt;-\n  emissions_longer %&gt;%\n  filter(year &gt;= 2000) %&gt;%\n  mutate(country = as.factor(country)) %&gt;%\n  filter(!str_detect(country, pattern = \"(Africa Eastern and Southern)|(Africa Western and Central)|\n                     (Central Europe and the Baltics)|(Early-demographic dividend)|(Early-demographic dividend)|\n                     (East Asia & Pacific)|(East Asia & Pacific (excluding high income))|(East Asia & Pacific (IDA & IBRD countries))|\n                     (Euro area)|(Europe & Central Asia)|(Europe & Central Asia (excluding high income))|(Europe & Central Asia (IDA & IBRD countries))|\n                     (European Union)|(Fragile and conflict affected situations)|(Heavily indebted poor countries (HIPC))|(High income)|\n                     (IBRD only)|(IDA blend)|(IDA only)|(IDA total)|(Late-demographic dividend)|(Latin America & Caribbean)|\n                     (Latin America & Caribbean (excluding high income))|(Latin America & the Caribbean (IDA & IBRD countries))|\n                     (Least developed countries: UN classification)|(Low & middle income)|(Low income)|(Lower middle income)|\n                     (Middle East & North Africa)|(Middle East & North Africa (excluding high income))|(Middle East & North Africa (IDA & IBRD countries))|\n                     (Middle income)|(Not classified)|(OECD members)|(Other small states)|(Post-demographic dividend)|(Pre-demographic dividend)|\n                     (South Asia)|(South Asia (IDA & IBRD))|(Sub-Saharan Africa)|(Sub-Saharan Africa (excluding high income))|\n                     (Sub-Saharan Africa (IDA & IBRD countries))|(Upper middle income)\")) %&gt;% \n  arrange(desc(recent_percent_increase)) %&gt;%\n  distinct(country, .keep_all =F) %&gt;%\n  slice_head(n = 6) %&gt;%\n  pull()\n\n\n\nlargest_dec &lt;-\n  emissions_longer %&gt;%\n  filter(year &gt;= 2000) %&gt;%\n  mutate(country = as.factor(country)) %&gt;%\n  filter(!str_detect(country, pattern = \"(Africa Eastern and Southern)|(Africa Western and Central)|\n                     (Central Europe and the Baltics)|(Early-demographic dividend)|(Early-demographic dividend)|\n                     (East Asia & Pacific)|(East Asia & Pacific (excluding high income))|(East Asia & Pacific (IDA & IBRD countries))|\n                     (Euro area)|(Europe & Central Asia)|(Europe & Central Asia (excluding high income))|(Europe & Central Asia (IDA & IBRD countries))|\n                     (European Union)|(Fragile and conflict affected situations)|(Heavily indebted poor countries (HIPC))|(High income)|\n                     (IBRD only)|(IDA blend)|(IDA only)|(IDA total)|(Late-demographic dividend)|(Latin America & Caribbean)|\n                     (Latin America & Caribbean (excluding high income))|(Latin America & the Caribbean (IDA & IBRD countries))|\n                     (Least developed countries: UN classification)|(Low & middle income)|(Low income)|(Lower middle income)|\n                     (Middle East & North Africa)|(Middle East & North Africa (excluding high income))|(Middle East & North Africa (IDA & IBRD countries))|\n                     (Middle income)|(Not classified)|(OECD members)|(Other small states)|(Post-demographic dividend)|(Pre-demographic dividend)|\n                     (South Asia)|(South Asia (IDA & IBRD))|(Sub-Saharan Africa)|(Sub-Saharan Africa (excluding high income))|\n                     (Sub-Saharan Africa (IDA & IBRD countries))|(Upper middle income)\")) %&gt;% \n  arrange(recent_percent_increase) %&gt;%\n  distinct(country, .keep_all =F) %&gt;%\n  slice_head(n = 6) %&gt;%\n  pull()"
  },
  {
    "objectID": "posts/blog_post_02/index.html#primary-visualizations",
    "href": "posts/blog_post_02/index.html#primary-visualizations",
    "title": "Blog Post 02",
    "section": "Primary Visualizations",
    "text": "Primary Visualizations\n\nemission_lat_long %&gt;%\n  filter(year == \"1990\" | year == \"2000\" | year == \"2010\" | year == \"2018\") %&gt;%\n  ggplot(aes(x = long, \n             y = lat,\n             group = group)) +\n  geom_polygon(aes(fill = metric_tons_pcapita)) +\n  coord_map(projection = \"mercator\", xlim=c(-180,180)) +\n  facet_wrap(~ year) +\n  theme_void() +\n  scale_fill_viridis_c(option = \"plasma\") +\n  labs(title = \"CO2 Emissions Per Capita by Country\",\n       fill = \"Metric Tons\\nper Capita\") +\n  theme(plot.title = element_text(hjust = 0.5))\n\n\n\n\n\n\n\n\n\nThis first plot ues a Mercator projection to view the metric tons of CO2 emitted by various countries in the years 1990, 2000, 2010, and 2018 on a map. I chose to view these years, because starting around 1990 the evidence and risks of human-caused warming first became widely known. It can be seen from the map, countries like Estonia, the UAE, and Luxembourg have higher metric tons of emissions per capita. This makes sense, because these countries are either relatively smaller in population or known for their oil production. When looking at some of the larger land-mass countries, it can be seen the USA and Russia seem to have decreased their emissions per capita over these years. On the contrary, countries like China, Saudi Arabai, and Kazakhstan have increased over the same period.\n\n\nemissions_longer %&gt;%\n  filter(year &gt;= 2000) %&gt;%\n  filter(country %in% largest_inc #| country %in% largest_dec\n         ) %&gt;%\n  ggplot(aes(x = year,\n             y = metric_tons_pcapita,\n             group = country,\n             color = country)) +\n  geom_line() +\n  facet_wrap(~country) +\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 6),\n        plot.title = element_text(hjust = 0.5)) +\n  labs(title= \"Countries with Largest Percent Increase in\\nMetric Tons of CO2 Per Capital from 2000 to 2018\",\n       y = \"Metric Tons of CO2 Per Capita\",\n       x = \"Year\",\n       color = \"Country\")\n\n\n\n\n\n\n\n\n\nWhile the Map above gives an interesting global view of emission changes throughout the years, it is more difficult to see the changes in emissions from smaller countries. I compare some of the emissions of countries with top percent increases in metric tons of CO2 per capita from the year 2000 to 2018. From this plot it can be seen Laos increased their CO2 emissions per capita drastically by nearly 2.5 metric tons over the the 18 year period which translated to a 14.74% increase. Vietnam also had a large emission increases over this period of just under 2.5 metric tons.\n\n\nemissions_longer %&gt;%\n  filter(year &gt;= 2000) %&gt;%\n  filter(country %in% largest_dec) %&gt;%\n  ggplot(aes(x = year,\n             y = metric_tons_pcapita,\n             group = country,\n             color = country)) +\n  geom_line() +\n  facet_wrap(~country) +\n\n  theme_minimal() +\n  theme(legend.position = \"none\",\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 7),\n        plot.title = element_text(hjust = 0.5)) +\n  labs(title= \"Countries with Largest Percent Decrease in\\nMetric Tons of CO2 Per Capital from 2000 to 2018\",\n       y = \"Metric Tons of CO2 Per Capita\",\n       x = \"Year\",\n       color = \"Country\")\n\n\n\n\n\n\n\n\n\nIn this plot, I compare some of the emissions of countries with top percent decreases in metric tons of CO2 per capita from the year 2000 to 2018. From this plot it can be seen Denmark decreased their CO2 emissions per capita drastically over the the 18 year period by over 3 metric tons, translating to a 41.64% decrease. Korea had the largest percent decrease in emissions at 77.36% from a roughly 2 metric ton decrease in C02 emission per capita."
  },
  {
    "objectID": "posts/blog_post_02/index.html#conclusion-and-wrap-up",
    "href": "posts/blog_post_02/index.html#conclusion-and-wrap-up",
    "title": "Blog Post 02",
    "section": "Conclusion and Wrap-Up",
    "text": "Conclusion and Wrap-Up\nNext time, for my faceted plots, I would like to add a second ‘y’ axis on the right hand side which would plot the percent change in emissions per capita. This would allow the reader to see both the change in raw metrics tons in addition to the percent change. In the future, I would like to also join together population data to compare how dependent these per capita metrics are based on each countries’ population. I would also love to acquire the lists of countries which belong to the groups and regions I excluded from my analysis to identify geographical trends in global emissions."
  },
  {
    "objectID": "posts/blog_post_02/index.html#connections-to-class-ideas",
    "href": "posts/blog_post_02/index.html#connections-to-class-ideas",
    "title": "Blog Post 02",
    "section": "Connections to Class Ideas",
    "text": "Connections to Class Ideas\nIn my first map plot, I implemented a Mercator projection of the globe and colored each country by its metric tons of CO2 emissions per capita. This map served as an effective visualization, because it allowed me to observe the fact that countries with smaller land-mass (and most likely population) often had higher CO2 emissions per capita. Without this, my hypothesis about population would potentially have overlooked. My next plots utilized line graphs and facet wrapping of the top percentage changes in CO2 emissions per capita. Doing this allowed me to present this 18 year time series data in a fashion where is was uncluttered and easy to interpret."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ds334blog",
    "section": "",
    "text": "Blog Post 04\n\n\n\n\n\n\nPolitics\n\n\n\n\n\n\n\n\n\nMay 10, 2024\n\n\nBen Sunshine\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 03\n\n\n\n\n\n\nModeling\n\n\n\n\n\n\n\n\n\nMar 8, 2024\n\n\nBen Sunshine\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 02\n\n\n\n\n\n\nEnvironmental\n\n\nMapping\n\n\n\n\n\n\n\n\n\nFeb 23, 2024\n\n\nBen Sunshine\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 01\n\n\n\n\n\n\nSports\n\n\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nBen Sunshine\n\n\n\n\n\n\nNo matching items"
  }
]